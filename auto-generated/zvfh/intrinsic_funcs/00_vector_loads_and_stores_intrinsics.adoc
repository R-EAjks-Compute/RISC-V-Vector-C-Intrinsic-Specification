
=== Vector Loads and Stores Intrinsics

[[vector-unit-stride-load]]
==== Vector Unit-Stride Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16_v_f16mf4(const _Float16 *rs1, size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2(const _Float16 *rs1, size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1(const _Float16 *rs1, size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2(const _Float16 *rs1, size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4(const _Float16 *rs1, size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8(const _Float16 *rs1, size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                       size_t vl);
vfloat16m1_t __riscv_vle16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m2_t __riscv_vle16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m4_t __riscv_vle16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                     size_t vl);
vfloat16m8_t __riscv_vle16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                     size_t vl);
----

[[vector-unit-stride-store]]
==== Vector Unit-Stride Store Intrinsics

[,c]
----
void __riscv_vse16_v_f16mf4(_Float16 *rs1, vfloat16mf4_t vs3, size_t vl);
void __riscv_vse16_v_f16mf2(_Float16 *rs1, vfloat16mf2_t vs3, size_t vl);
void __riscv_vse16_v_f16m1(_Float16 *rs1, vfloat16m1_t vs3, size_t vl);
void __riscv_vse16_v_f16m2(_Float16 *rs1, vfloat16m2_t vs3, size_t vl);
void __riscv_vse16_v_f16m4(_Float16 *rs1, vfloat16m4_t vs3, size_t vl);
void __riscv_vse16_v_f16m8(_Float16 *rs1, vfloat16m8_t vs3, size_t vl);
// masked functions
void __riscv_vse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vfloat16mf4_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vfloat16mf2_t vs3,
                              size_t vl);
void __riscv_vse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vfloat16m1_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vfloat16m2_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vfloat16m4_t vs3,
                             size_t vl);
void __riscv_vse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vfloat16m8_t vs3,
                             size_t vl);
----

[[vector-strided-load]]
==== Vector Strided Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vlse16_v_f16mf4(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2(const _Float16 *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8(const _Float16 *rs1, ptrdiff_t rs2,
                                    size_t vl);
// masked functions
vfloat16mf4_t __riscv_vlse16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16mf2_t __riscv_vlse16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                        ptrdiff_t rs2, size_t vl);
vfloat16m1_t __riscv_vlse16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m2_t __riscv_vlse16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m4_t __riscv_vlse16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat16m8_t __riscv_vlse16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                      ptrdiff_t rs2, size_t vl);
----

[[vector-strided-store]]
==== Vector Strided Store Intrinsics

[,c]
----
void __riscv_vsse16_v_f16mf4(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf4_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16mf2(_Float16 *rs1, ptrdiff_t rs2, vfloat16mf2_t vs3,
                             size_t vl);
void __riscv_vsse16_v_f16m1(_Float16 *rs1, ptrdiff_t rs2, vfloat16m1_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m2(_Float16 *rs1, ptrdiff_t rs2, vfloat16m2_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m4(_Float16 *rs1, ptrdiff_t rs2, vfloat16m4_t vs3,
                            size_t vl);
void __riscv_vsse16_v_f16m8(_Float16 *rs1, ptrdiff_t rs2, vfloat16m8_t vs3,
                            size_t vl);
// masked functions
void __riscv_vsse16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsse16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, ptrdiff_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m1_t vs3, size_t vl);
void __riscv_vsse16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m2_t vs3, size_t vl);
void __riscv_vsse16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m4_t vs3, size_t vl);
void __riscv_vsse16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, ptrdiff_t rs2,
                              vfloat16m8_t vs3, size_t vl);
----

[[vector-indexed-load]]
==== Vector Indexed Load Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vloxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4(const _Float16 *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2(const _Float16 *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1(const _Float16 *rs1, vuint16m1_t rs2,
                                      size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2(const _Float16 *rs1, vuint16m2_t rs2,
                                      size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4(const _Float16 *rs1, vuint16m4_t rs2,
                                      size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8(const _Float16 *rs1, vuint16m8_t rs2,
                                      size_t vl);
// masked functions
vfloat16mf4_t __riscv_vloxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vloxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vloxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vloxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vloxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vloxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
vfloat16mf4_t __riscv_vluxei16_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                          vuint16mf4_t rs2, size_t vl);
vfloat16mf2_t __riscv_vluxei16_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                          vuint16mf2_t rs2, size_t vl);
vfloat16m1_t __riscv_vluxei16_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                        vuint16m1_t rs2, size_t vl);
vfloat16m2_t __riscv_vluxei16_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                        vuint16m2_t rs2, size_t vl);
vfloat16m4_t __riscv_vluxei16_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                        vuint16m4_t rs2, size_t vl);
vfloat16m8_t __riscv_vluxei16_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                        vuint16m8_t rs2, size_t vl);
----

[[vector-indexed-store]]
==== Vector Indexed Store Intrinsics

[,c]
----
void __riscv_vsoxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsoxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16mf4(_Float16 *rs1, vuint16mf4_t rs2,
                               vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2(_Float16 *rs1, vuint16mf2_t rs2,
                               vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1(_Float16 *rs1, vuint16m1_t rs2, vfloat16m1_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m2(_Float16 *rs1, vuint16m2_t rs2, vfloat16m2_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m4(_Float16 *rs1, vuint16m4_t rs2, vfloat16m4_t vs3,
                              size_t vl);
void __riscv_vsuxei16_v_f16m8(_Float16 *rs1, vuint16m8_t rs2, vfloat16m8_t vs3,
                              size_t vl);
// masked functions
void __riscv_vsoxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsoxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf4_m(vbool64_t vm, _Float16 *rs1, vuint16mf4_t rs2,
                                 vfloat16mf4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16mf2_m(vbool32_t vm, _Float16 *rs1, vuint16mf2_t rs2,
                                 vfloat16mf2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m1_m(vbool16_t vm, _Float16 *rs1, vuint16m1_t rs2,
                                vfloat16m1_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m2_m(vbool8_t vm, _Float16 *rs1, vuint16m2_t rs2,
                                vfloat16m2_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m4_m(vbool4_t vm, _Float16 *rs1, vuint16m4_t rs2,
                                vfloat16m4_t vs3, size_t vl);
void __riscv_vsuxei16_v_f16m8_m(vbool2_t vm, _Float16 *rs1, vuint16m8_t rs2,
                                vfloat16m8_t vs3, size_t vl);
----

[[unit-stride-fault-only-first-loads]]
==== Unit-stride Fault-Only-First Loads Intrinsics

[,c]
----
vfloat16mf4_t __riscv_vle16ff_v_f16mf4(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2(const _Float16 *rs1, size_t *new_vl,
                                       size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8(const _Float16 *rs1, size_t *new_vl,
                                     size_t vl);
// masked functions
vfloat16mf4_t __riscv_vle16ff_v_f16mf4_m(vbool64_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16mf2_t __riscv_vle16ff_v_f16mf2_m(vbool32_t vm, const _Float16 *rs1,
                                         size_t *new_vl, size_t vl);
vfloat16m1_t __riscv_vle16ff_v_f16m1_m(vbool16_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m2_t __riscv_vle16ff_v_f16m2_m(vbool8_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m4_t __riscv_vle16ff_v_f16m4_m(vbool4_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
vfloat16m8_t __riscv_vle16ff_v_f16m8_m(vbool2_t vm, const _Float16 *rs1,
                                       size_t *new_vl, size_t vl);
----
